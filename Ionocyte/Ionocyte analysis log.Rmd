---
title: "Ionocyte Analysis Log"
author: "Teresa G. Schwemmer"
date: "1/21/2022"
output: html_document
---

January 21, 2022

-I added the csvs for embryo, 1dph, and 10mm to the environment and saved the environment so I can easily pull it up each time. 
-First overall goal is to analyze the standard deviations between duplicate counts to see which ones need to be recounted. 
    -I think these data sheets don't include that having already been done at all but I'll have to check for sure. 
    -Embryo definitely doesn't because I pulled it right from the raw data sheets. 
    -Relatedly, I need to figure out how to address outliers (both the overall outliers and outliers identified in the statistical analysis). 
-Next overall goal will be to analyze the average densities for each section and the total fish, with respect to the treatments. 
    -Temperature: 17C, 20C, 24C, 28C
    -CO2: 400, 2200, 4200 uatm
    -Experiment: 1, 2, 3, 4 
    -Section: front, back, total OR yolk, body, total
    -I will have to decide whether to include all and analyze as continuous data, or exclude unbalanced data and use LME models. 
-Third overall goal will be to analyze relationships between ionocyte density and metabolism and gene expression, within and across treatments. 

-Units: for now I will use square mm as the area units. 

-Embryo SD analysis
    -Yolk: There are 4 above 400, 7 above 300
      -Try putting a line at 3 SDs away from the mean SD
      -This line is around 300
      -Samples: 2016-373, 2016-456, 2016-457, 2016-458, 2016-525, 2016-542, 2016-544
        -2016-373: The second count is lower and area is higher so density is much lower. Analyzed R side both times. Actually looks like the second count was for the L side but entered into R side columns by accident. I will use the L side instead since that was counted twice. Done.
        -2016-456: Yolk Density 2 is much lower than 1, count is lower and area is higher. Used L for 1 and R for 2. Should probably pick one to redo so sides match. Replaced R with L for 2nd count. Done. 
        -2016-457: Yolk density 2 is much lower than 1, probably because first is R and second is L. L side has better view and less squished so I will redo that one. Done. 
        -2016-458: Yolk density 2 is much lower than 1, probably because first is R and second is L. The staining is really faint on L so I will redo R. Done. 
    -Body: There is 1 above 800, 2 above 300
      -the line at 3SDs away from the mean SD is also around 300
      -Samples: 2016-380, 2016-517
    -Total: Actually there's no need to do this because I just want to compare duplicate count pairs. 
    
-Note on Git: The local repository set up through GitHub Desktop (Documents/GitHub/MenidiaOA) is separate from the R Project repository (Documents/MenidiaOA). Do not make changes to both at the same time, just work in one or the other, and remember to pull when getting started in either one. 

-1dph SD analysis
    -They were already corrected when I did this in 2021, but 2017 data weren't included then. 
    -I calculated a new mean+3SD threshold to check if any 2017 samples are above it. 
    -Front: 2017-373 is above it, examine it for large difference
    -Back: none. 
    
-10mm SD analysis
    -I did look at this in 2021. But I am not sure if I fixed the ones that had high SD. 
    -The data now includes all duplicates so if I rerun it I will get different results regardless.
    -I saved the environment from before fixing data so I can check if the data are the same. 
    -Actually I also have an environment from after fixing the data so I guess I did. 
    -Also this data shows duplicate counts for all samples. 
    -Some of the samples seem to be fixed and others aren't (see analysis script for details). 
    -So I will need to check the spreadsheet in Google Drive when I go through them more thoroughly and make sure that version isn't fixed so I don't duplicate effort. 
    -Front: 2016-105t, 2016-165t
    -Back: 2016-56t, 2016-57t, 2016-75t, 2016-77t, 2016-233t, 2016-307t, 2016-390t

-I will directly edit the CSVs of the data when I make changes, but create a new saved environment when I reload them into R. 
